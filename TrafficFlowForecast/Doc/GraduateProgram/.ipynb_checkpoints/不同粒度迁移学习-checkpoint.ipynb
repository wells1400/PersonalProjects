{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import load_model\n",
    "from Plot_Self_Correlation import plot_auto_corr\n",
    "from DP_LSTM import *\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Station605_pd = pd.read_csv(r'D:\\WORK__wells\\PROGRAM_3\\Data\\station605_pd_pure.csv')\n",
    "Station605_pd.rename(columns={'F10':'TrafficFlow','F1':'DateTime'},inplace=True)\n",
    "Station605_pd.drop(['F2','F5','F6'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Station605_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''数据处理模块'''\n",
    "#对实验数据进行归一化处理\n",
    "def Raw_Data_Normalized(Raw_df):\n",
    "    Raw_pd = Raw_df.copy()\n",
    "    Raw_pd_empty = Raw_pd.loc[Raw_pd.TrafficFlow.isna()]\n",
    "    Raw_pd_Nonempty = Raw_pd.drop(Raw_pd_empty.index,axis=0)\n",
    "    MMScaler = MinMaxScaler(feature_range=(1,2))\n",
    "    MMScaled_Data = MMScaler.fit_transform(np.reshape(Raw_pd_Nonempty['TrafficFlow'].get_values(),(Raw_pd_Nonempty.TrafficFlow.shape[0],1)))\n",
    "    Raw_pd_Nonempty['TrafficFlow'] = MMScaled_Data\n",
    "    Raw_pd = pd.concat([Raw_pd_Nonempty, Raw_pd_empty])\n",
    "    return Raw_pd,MMScaler\n",
    "\n",
    "def GetTimeSeriesData(Normalized_5pd, TimeLag):\n",
    "    # 输入 标准化后的完整数据、时滞TimeLag\n",
    "    # 输出 时间序列数据 np.array\n",
    "    sequence_length = TimeLag + 1\n",
    "    result = []\n",
    "    for index in range(len(Normalized_5pd) - sequence_length):\n",
    "        result.append(Normalized_5pd.TrafficFlow[index: index + sequence_length])\n",
    "    result = np.array(result)\n",
    "    return result\n",
    "\n",
    "def RandomEntire(df_t, EmptyProportion):\n",
    "    #整体缺失一部分 返回pd (DateTime, Traffic_True, TrafficFlow)\n",
    "    df = df_t.copy()\n",
    "    DropNum =  round(df.shape[0]*EmptyProportion)\n",
    "    df_len = df.shape[0]\n",
    "    Save_pd = df.drop([df_len-1-i for i in range(DropNum)],axis=0)\n",
    "    df.rename(columns={'TrafficFlow':'Traffic_True'},inplace=True)\n",
    "    #df_cp = df.drop(['TraficFlow'],axis=1)\n",
    "    Save_pd = pd.merge(df, Save_pd,on=['DateTime'],how='outer')\n",
    "    Save_pd.sort_values(by=['DateTime'],inplace=True)\n",
    "    Save_pd.index = [i for i in range(len(Save_pd))]\n",
    "    return Save_pd\n",
    "\n",
    "#输入构造不同粒度的数据记录,分别控制不同的缺失比例\n",
    "def Get_HigherScaleRecord(Normalized_605pd,Time_scale):\n",
    "    # 输入标准化后的完整数据  构造Time_scale粒度的数据记录\n",
    "    # 输出新粒度数据pd\n",
    "    new_grid_pd = pd.DataFrame(columns=['DateTime','TrafficFlow','Traffic_True'])\n",
    "    line_grid_pd = pd.DataFrame(columns=['DateTime','TrafficFlow','Traffic_True'])\n",
    "    for i in range(Normalized_605pd.shape[0]):\n",
    "        if (i+1)% Time_scale== 0:\n",
    "            selected_pd =  Normalized_605pd.loc[[i-j+1 for j in range(Time_scale, 0,-1)]]    \n",
    "            line_grid_pd['TrafficFlow'] = [selected_pd.TrafficFlow.sum()]\n",
    "            line_grid_pd['Traffic_True'] = [selected_pd.Traffic_True.sum()]\n",
    "                #print(df.loc[[i,i+1,i+2]].DateTime.get_values()[0])\n",
    "            line_grid_pd['DateTime'] = [Normalized_605pd.loc[[i-Time_scale+1]].DateTime.get_values()[0]]\n",
    "                #print(line_grid_pd)\n",
    "            new_grid_pd = pd.concat([new_grid_pd, line_grid_pd])\n",
    "    new_grid_pd.index = [i for i in range(len(new_grid_pd))]\n",
    "    new_grid_pd = new_grid_pd.replace(0,np.nan)\n",
    "#     df_list[str(Time_scale)] =  new_grid_pd\n",
    "    return new_grid_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrePareLSTM(Station5_pd, TimeLag, params):\n",
    "    print(r'预训练模型')\n",
    "    Normalized_5pd,MM5Scaler = Raw_Data_Normalized(Station5_pd)\n",
    "#     print(Normalized_5pd.head())\n",
    "    TimeSeries5Data = GetTimeSeriesData(Normalized_5pd, TimeLag)\n",
    "    PreTrain_X = TimeSeries5Data[:,:-1]\n",
    "    PreTrain_Y = TimeSeries5Data[:,-1]\n",
    "    \n",
    "    PreTrain_X = np.reshape(PreTrain_X, (PreTrain_X.shape[0], 1,PreTrain_X.shape[1]))\n",
    "    PreTrain_Y = np.reshape(PreTrain_Y, (PreTrain_Y.shape[0], 1,1))\n",
    "    \n",
    "    TransferModel = build_LSTM_Model(inputDim = PreTrain_X.shape[2],lr=params['lr'],\n",
    "                                     nb_hidden_cell=params['nb_hidden_cell'],\n",
    "                                     nb_layers=params['nb_layers'])\n",
    "    PrepairedModel = model_fit(TransferModel,PreTrain_X,PreTrain_Y,\n",
    "                               validation_split=0.2,\n",
    "                               saveFile='D:\\WORK__wells\\PROGRAM_3\\Model pic',\n",
    "                               epochs=params['epochs'],batch_size=params['batch_size'])\n",
    "    print(r'预训练模型学习完毕！') \n",
    "    return PrepairedModel\n",
    "\n",
    "'''\n",
    "迁移学习微调实验模型\n",
    "\n",
    "'''\n",
    "\n",
    "def FineTune(Prepared_model, Train_X, Train_Y,params):\n",
    "    from keras.layers import Dense\n",
    "    model_new = Prepared_model\n",
    "    model_new.pop()\n",
    "    for i in range(len(Prepared_model.layers)-1):  # 除最后一层外，权重全部导入\n",
    "        model_new.layers[i].set_weights(Prepared_model.layers[i].get_weights())\n",
    "        if i < params['frozenlayer']:\n",
    "            model_new.layers[i].trainable=False\n",
    "    \n",
    "        # model_new.add(Dense(5, activation='sigmoid', name='last2'))\n",
    "    model_new.add(Dense(1,activation='linear'))\n",
    "#     saveFile = 'D:/CPQ/air/hour_tranfer_hour'\n",
    "    #调整迁移预测数据准备\n",
    "    # 标准化进行预测\n",
    "        \n",
    "    ReTrain_X = np.reshape(Train_X, (Train_X.shape[0], 1,Train_X.shape[1]))\n",
    "    ReTrain_Y = np.reshape(Train_Y, (Train_Y.shape[0], 1,1))\n",
    "    print('微调迁移学习模型')\n",
    "    Prepared_model = model_fit(model_new, ReTrain_X, \n",
    "                                   ReTrain_Y,epochs=params['TransferEpochs'], \n",
    "                                   batch_size=params['TransferBatch_size'])\n",
    "    return Prepared_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在10分钟 30分钟 一个小时 一天的范围内 比较直接预测模型与基于迁移学习的模型（基模型为5分钟粒度）的性能\n",
    "# 构造\n",
    "\n",
    "'''\n",
    "输入：\n",
    "1、 Station605_pd\n",
    "2、时滞 TimeLag\n",
    "3、要构造的粒度 列表 GridList\n",
    "3、params\n",
    "\n",
    "输出：不同粒度下直接LSTM与迁移学习LSTM性能的比较\n",
    "'''\n",
    "def TransferLearning(Station605_pd,TimeLag,GridList,params,FrozenLayers=3):\n",
    "    # 准备迁移学习基本模型\n",
    "    PrepairedModel = PrePareLSTM(Station605_pd, TimeLag, params)\n",
    "    result_pd = pd.DataFrame(columns=['Grid','Direct_RMSE','Direct_MAE','Direct_MAPE','RMSE','MAE','MAPE'])\n",
    "    line_pd = pd.DataFrame(columns=['Grid','Direct_RMSE','Direct_MAE','Direct_MAPE','RMSE','MAE','MAPE'])\n",
    "    #\n",
    "    Empty_pd = RandomEntire(Station605_pd,0)\n",
    "    # 构造不同粒度的数据\n",
    "    for EachGrid in GridList:\n",
    "        print(r'准备数据')\n",
    "        HighGrid_pd = Get_HigherScaleRecord(Empty_pd, EachGrid)\n",
    "        Normalized_605pd,MM5Scaler = Raw_Data_Normalized(HighGrid_pd)\n",
    "        TimeSeries605Data = GetTimeSeriesData(Normalized_605pd, TimeLag)\n",
    "        Tmp_pd = pd.DataFrame(TimeSeries605Data)\n",
    "        # 切分训练验证数据\n",
    "        Train_pd = Tmp_pd.sample(frac = 0.8,replace=False)\n",
    "        Test_pd = Tmp_pd.drop(Train_pd.index,axis=0)\n",
    "        # 准备训练数据 验证数据\n",
    "        Train_X = Train_pd.get_values()[:,:-1]\n",
    "        Train_Y = Train_pd.get_values()[:,-1]\n",
    "        \n",
    "        Validation_X = Test_pd.get_values()[:,:-1]\n",
    "        Validation_Y = Test_pd.get_values()[:,-1]\n",
    "        # 微调模型\n",
    "        TranseferedModel = FineTune(PrepairedModel, Train_X, Train_Y,params)\n",
    "        \n",
    "        #直接预测\n",
    "        Train_X = np.reshape(Train_X, (Train_X.shape[0], 1,Train_X.shape[1]))\n",
    "        Train_Y = np.reshape(Train_Y, (Train_Y.shape[0], 1,1))\n",
    "        \n",
    "        Validation_X = np.reshape(Validation_X, (Validation_X.shape[0], 1,Validation_X.shape[1]))\n",
    "        Validation_Y = np.reshape(Validation_Y, (Validation_Y.shape[0], 1,1))\n",
    "        print(r'直接预测')\n",
    "        Model = build_LSTM_Model(inputDim = Train_X.shape[2],lr=params['lr'],nb_hidden_cell=params['nb_hidden_cell'],nb_layers= params['nb_layers'])\n",
    "        fit_model = model_fit(Model,Train_X, Train_Y, validation_split=0.1, epochs=params['epochs'], batch_size=params['batch_size'])\n",
    "        \n",
    "        RMSE,MAE,MAPE,Predict_y,True_Y = model_predict(fit_model,Validation_X,Validation_Y,MM5Scaler)\n",
    "        line_pd['Direct_RMSE'] = [RMSE]\n",
    "        line_pd['Direct_MAE'] = [MAE]\n",
    "        line_pd['Direct_MAPE'] = [MAPE]\n",
    "        line_pd['Grid'] = [EachGrid]\n",
    "        print(r'迁移学习预测')\n",
    "        RMSE,MAE,MAPE,Predict_y,True_Y = model_predict(TranseferedModel,Validation_X,Validation_Y,MM5Scaler)\n",
    "        line_pd['RMSE'] = [RMSE]\n",
    "        line_pd['MAE'] = [MAE]\n",
    "        line_pd['MAPE'] = [MAPE]\n",
    "        \n",
    "        result_pd = pd.concat([result_pd, line_pd])\n",
    "        result_pd.to_csv(r'D:\\WORK__wells\\PROGRAM_3\\Result\\result\\ResultGrid.csv',index=None)\n",
    "        # 对于整体数据 直接预测和迁移学习预测分别出下图\n",
    "        print(r'整体图')\n",
    "        Entire_X = TimeSeries605Data[:,:-1]\n",
    "        Entire_Y = TimeSeries605Data[:,-1]\n",
    "        Entire_X = np.reshape(Entire_X, (Entire_X.shape[0], 1,Entire_X.shape[1]))\n",
    "        Entire_Y = np.reshape(Entire_Y, (Entire_Y.shape[0], 1,1))\n",
    "        # 直接预测，迁移学习预测\n",
    "        RMSE,MAE,MAPE,Predict_y,True_Y = model_predict(fit_model,Entire_X,Entire_Y,MM5Scaler)\n",
    "        RMSE,MAE,MAPE,TransferPredict_y,True_Y = model_predict(TranseferedModel,Entire_X,Entire_Y,MM5Scaler)\n",
    "        resultDic = {\n",
    "                     'True_Y':True_Y,\n",
    "                     'DirectPredict':Predict_y,\n",
    "                     'TrnsferPredict': TransferPredict_y\n",
    "                     \n",
    "                    }\n",
    "        resultDic['True_Y'] = resultDic['True_Y'].reshape(resultDic['True_Y'].shape[0])\n",
    "        resultDic['DirectPredict'] = resultDic['DirectPredict'].reshape(resultDic['DirectPredict'].shape[0])\n",
    "        resultDic['TrnsferPredict'] = resultDic['TrnsferPredict'].reshape(resultDic['TrnsferPredict'].shape[0])\n",
    "        \n",
    "        ForPlot_pd = pd.DataFrame(resultDic)\n",
    "        ForPlot_pd.to_csv(r'D:\\WORK__wells\\PROGRAM_3\\Result\\result\\ForPlot'+str(EachGrid)+'.csv',index=None)\n",
    "        Normalized_605pd.to_csv(r'D:\\WORK__wells\\PROGRAM_3\\Result\\result\\日期数据'+str(EachGrid)+'.csv',index=None)\n",
    "    return result_pd,Normalized_605pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {'lr': 0.001,\n",
    "          'nb_hidden_cell': [80,80],\n",
    "          'nb_layers': 2,\n",
    "          'epochs': 10,\n",
    "          'batch_size': 30,\n",
    "          'TransferEpochs':20,\n",
    "          'TransferBatch_size':2,\n",
    "          'frozenlayer':3}\n",
    "\n",
    "TimeLag = 5\n",
    "# GridList = [2, 6, 12, 36,288]\n",
    "GridList = [2]\n",
    "result_pd,Normalized_605pd = TransferLearning(Station605_pd,TimeLag,GridList,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不同时滞下LSTM的预测效果\n",
    "def TimeLagPlot(Station605_pd,TimeLags,params):\n",
    "\n",
    "    result_pd = pd.DataFrame(columns=['TimeLags','Direct_RMSE','Direct_MAE','Direct_MAPE'])\n",
    "    line_pd = pd.DataFrame(columns=['TimeLags','Direct_RMSE','Direct_MAE','Direct_MAPE'])\n",
    "    #\n",
    "    Empty_pd = RandomEntire(Station605_pd,0)\n",
    "    Normalized_605pd,MM5Scaler = Raw_Data_Normalized(Empty_pd)\n",
    "    for EachLag in TimeLags:\n",
    "        print(r'准备数据')\n",
    "        TimeSeries605Data = GetTimeSeriesData(Normalized_605pd, EachLag)\n",
    "        Tmp_pd = pd.DataFrame(TimeSeries605Data)\n",
    "        # 切分训练验证数据\n",
    "        Train_pd = Tmp_pd.sample(frac = 0.8,replace=False)\n",
    "        Test_pd = Tmp_pd.drop(Train_pd.index,axis=0)\n",
    "        # 准备训练数据 验证数据\n",
    "        Train_X = Train_pd.get_values()[:,:-1]\n",
    "        Train_Y = Train_pd.get_values()[:,-1]\n",
    "        \n",
    "        Validation_X = Test_pd.get_values()[:,:-1]\n",
    "        Validation_Y = Test_pd.get_values()[:,-1]\n",
    "        \n",
    "        #直接预测\n",
    "        Train_X = np.reshape(Train_X, (Train_X.shape[0], 1,Train_X.shape[1]))\n",
    "        Train_Y = np.reshape(Train_Y, (Train_Y.shape[0], 1,1))\n",
    "        \n",
    "        Validation_X = np.reshape(Validation_X, (Validation_X.shape[0], 1,Validation_X.shape[1]))\n",
    "        Validation_Y = np.reshape(Validation_Y, (Validation_Y.shape[0], 1,1))\n",
    "        print(r'直接预测')\n",
    "        Model = build_LSTM_Model(inputDim = Train_X.shape[2],lr=params['lr'],nb_hidden_cell=params['nb_hidden_cell'],nb_layers= params['nb_layers'])\n",
    "        fit_model = model_fit(Model,Train_X, Train_Y, validation_split=0.1, epochs=params['epochs'], batch_size=params['batch_size'])\n",
    "        \n",
    "        RMSE,MAE,MAPE,Predict_y,True_Y = model_predict(fit_model,Validation_X,Validation_Y,MM5Scaler)\n",
    "        line_pd['Direct_RMSE'] = [RMSE]\n",
    "        line_pd['Direct_MAE'] = [MAE]\n",
    "        line_pd['Direct_MAPE'] = [MAPE]\n",
    "        line_pd['TimeLags'] = [EachLag]\n",
    "        \n",
    "        result_pd = pd.concat([result_pd, line_pd])\n",
    "        result_pd.to_csv(r'D:\\WORK__wells\\PROGRAM_3\\Result\\result\\不同时滞.csv',index=None)\n",
    "        \n",
    "    return result_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {'lr': 0.001,\n",
    "          'nb_hidden_cell': [80,80,80,80,80,80],\n",
    "          'nb_layers': 6,\n",
    "          'epochs': 20,\n",
    "          'batch_size': 100,\n",
    "          'TransferEpochs':20,\n",
    "          'TransferBatch_size':30,\n",
    "          'frozenlayer':3}\n",
    "\n",
    "\n",
    "# GridList = [2, 6, 12, 36,288]\n",
    "TimeLags = [i+25 for i in range(34)]\n",
    "result_pd = TimeLagPlot(Station605_pd,TimeLags,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
