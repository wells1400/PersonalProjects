{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import word2vec\n",
    "import gensim\n",
    "import logging\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from DataProcess import DataProcess\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "from keras.preprocessing.text import one_hot\n",
    "from DP_LSTM import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D,Conv2D,Conv1D,GlobalMaxPooling1D,Input\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新闻处理\n",
    "data_processor = DataProcess(\n",
    "                             dow_jons_path=r'/home/wells/SIOA/DowJonesPredict/SourceData/DowJones.csv',\n",
    "                             news_path=r'/home/wells/SIOA/DowJonesPredict/SourceData/News.csv',\n",
    "                             save_model_file=r'/home/wells/SIOA/DowJonesPredict/SourceData//',\n",
    "                            # padding_size = 1500,\n",
    "                            # vector_size = 64\n",
    "                            )\n",
    "dow_jons_pd = data_processor.run_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>price_flag</th>\n",
       "      <th>today_news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>17924.240234</td>\n",
       "      <td>0</td>\n",
       "      <td>117 year old woman mexico city finally receive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>17712.759766</td>\n",
       "      <td>0</td>\n",
       "      <td>jamaica proposes marijuana dispensers tourists...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-06-29</td>\n",
       "      <td>17456.019531</td>\n",
       "      <td>0</td>\n",
       "      <td>explosion airport istanbul yemeni former presi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>17190.509766</td>\n",
       "      <td>1</td>\n",
       "      <td>2 500 scientists australia want save great bar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>17355.210938</td>\n",
       "      <td>1</td>\n",
       "      <td>barclays rbs shares suspended trading tanking ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date          Open  price_flag  \\\n",
       "0  2016-07-01  17924.240234           0   \n",
       "1  2016-06-30  17712.759766           0   \n",
       "2  2016-06-29  17456.019531           0   \n",
       "3  2016-06-28  17190.509766           1   \n",
       "4  2016-06-27  17355.210938           1   \n",
       "\n",
       "                                          today_news  \n",
       "0  117 year old woman mexico city finally receive...  \n",
       "1  jamaica proposes marijuana dispensers tourists...  \n",
       "2  explosion airport istanbul yemeni former presi...  \n",
       "3  2 500 scientists australia want save great bar...  \n",
       "4  barclays rbs shares suspended trading tanking ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dow_jons_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计news 中有多少不相同的词\n",
    "def count_diff_words(data_pd):\n",
    "    res_num = 0\n",
    "    word_set = set()\n",
    "    for sentence in data_pd.today_news:\n",
    "        words = sentence.split()\n",
    "        for word in words:\n",
    "            if word not in word_set:\n",
    "                res_num += 1\n",
    "                word_set.add(word)\n",
    "    return res_num\n",
    "\n",
    "\n",
    "# 处理新闻DataFrame,转成index arrary\n",
    "def propose_news_array(dow_jons_pd,max_length):\n",
    "    vocab_size = count_diff_words(dow_jons_pd)\n",
    "    encoded_docs = [one_hot(d, vocab_size) for d in dow_jons_pd.today_news]\n",
    "    padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "    return padded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_Cnn_Model(params):\n",
    "    # cnn 模型部分\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Embedding(params['cnn_param']['embedding']['imput_dim'], \n",
    "                        params['cnn_param']['embedding']['output_dim'], \n",
    "                        input_length=params['cnn_param']['embedding']['imput_length']))\n",
    "    cnn_model.add(Conv1D(params['cnn_param']['n_filter'],params['cnn_param']['kernel_size'],padding='valid',activation='relu',use_bias=True))\n",
    "    cnn_model.add(GlobalMaxPooling1D())\n",
    "\n",
    "    cnn_model.add(Dense(params['cnn_param']['dense_dim'], activation='relu'))\n",
    "    cnn_model.add(Dropout(rate=0.25))\n",
    "    cnn_model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "    adam_optimizer = Adam(lr=params['cnn_param']['lr'])\n",
    "    cnn_model.compile(loss='binary_crossentropy',optimizer=adam_optimizer, metrics=['accuracy'])\n",
    "    print(cnn_model.summary())\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型融合\n",
    "def build_fusion_model(params):\n",
    "    from keras.optimizers import RMSprop,Adam\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense,concatenate,Reshape,Convolution2D\n",
    "    from keras.layers.recurrent import LSTM\n",
    "    from keras.layers.recurrent import GRU\n",
    "    from keras.layers.core import Dropout\n",
    "    from keras.backend import reshape\n",
    "    from keras.utils import plot_model\n",
    "    \n",
    "    # cnn模型部分\n",
    "    cnn_input = Input(shape=(params['cnn_param']['embedding']['imput_length'],))\n",
    "    cnn_embedding = Embedding(params['cnn_param']['embedding']['imput_dim'], \n",
    "                        params['cnn_param']['embedding']['output_dim'], \n",
    "                        input_length=(params['cnn_param']['embedding']['imput_length']))(cnn_input)\n",
    "    \n",
    "    reshape_cnn = Reshape((params['cnn_param']['embedding']['imput_length'],params['cnn_param']['embedding']['output_dim'],1))(cnn_embedding)\n",
    "    conv_1 = Convolution2D(\n",
    "#                            batch_input_shape=(None, params['cnn_param']['embedding']['imput_length'],\n",
    "#                                               params['cnn_param']['embedding']['output_dim'],1),\n",
    "                           filters=params['cnn_param']['n_filter'],\n",
    "                           kernel_size=params['cnn_param']['kernel_size'],\n",
    "                           strides=1,\n",
    "                           padding='same',\n",
    "                           data_format='channels_last',\n",
    "                          )(reshape_cnn)\n",
    "    max_pool_1 = MaxPooling2D(pool_size=(params['cnn_param']['n_pool'], params['cnn_param']['n_pool']))(conv_1)\n",
    "    #cnn_drop = Dropout(rate=0.25)(max_pool_1)\n",
    "    flat_cnn = Flatten()(max_pool_1)\n",
    "    cnn_dense = Dense(params['cnn_param']['dense_dim'],activation='tanh',use_bias=True)(flat_cnn)\n",
    "    reshape_cnn_dense = Reshape((1,params['cnn_param']['dense_dim']))(cnn_dense)\n",
    "    #predictions_layer = Dense(1,activation='sigmoid')(cnn_dense)\n",
    "    \n",
    "    # lstm模型部分\n",
    "    lstm_imput = Input(shape=(1,params['lstm_param']['TimeLag']))  # input_shape=(1,params['lstm_param']['TimeLag']),\n",
    "    lstm_layer_1 = LSTM(params['lstm_param']['nb_hidden_cell'][0],use_bias=True,activation='tanh',name='layer_0',return_sequences=True)(lstm_imput)\n",
    "    #lstm_layer_2 = LSTM(params['lstm_param']['nb_hidden_cell'][1],use_bias=True,activation='tanh',name='layer_1',return_sequences=True)(lstm_layer_1)\n",
    "    #lstm_layer_3 = LSTM(params['lstm_param']['nb_hidden_cell'][2],use_bias=True,activation='tanh',name='layer_2',return_sequences=True)(lstm_layer_2)\n",
    "    lstm_dense = Dense(params['lstm_param']['dense_dim'],use_bias=True,activation='linear',name='last')(lstm_layer_1)\n",
    "#     lstm_predict_layer = Dense(1,activation='linear')(lstm_dense)\n",
    "\n",
    "    fusion_layer = concatenate([reshape_cnn_dense, lstm_dense])\n",
    "    dense_layer = Dense(8,activation='linear')(fusion_layer)\n",
    "  #  print(fusion_layer.shape)\n",
    "    fusion_drop = Dropout(rate=0.1)(dense_layer)\n",
    "    predict_payer = Dense(1,activation='linear')(fusion_drop)\n",
    "    \n",
    "    fusion_model = Model(inputs=[cnn_input, lstm_imput], outputs=predict_payer)\n",
    "    adam_optimizer = Adam(lr=params['lr'])\n",
    "    fusion_model.compile(optimizer=adam_optimizer,loss='mse',metrics=['mae','mape'])\n",
    "    #print(fusion_model.summary())\n",
    "    \n",
    "    #plot_model(fusion_model, to_file='model.png',  show_shapes=True)\n",
    "    return fusion_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''数据处理模块'''\n",
    "#对实验数据进行归一化处理\n",
    "def Raw_Data_Normalized(Raw_df): # 标准化数据\n",
    "    Raw_pd = Raw_df.copy()\n",
    "    MMScaler = MinMaxScaler(feature_range=(0.1,1))\n",
    "    MMScaled_Data = MMScaler.fit_transform(np.reshape(Raw_pd['Open'].get_values(),(Raw_pd.Open.shape[0],1)))\n",
    "    Raw_pd['OpenScaled'] = MMScaled_Data\n",
    "    return Raw_pd,MMScaler\n",
    "\n",
    "def GetTimeSeriesData(Normalized_pd, TimeLag): #根据时滞创建时间序列数据\n",
    "    # 输入 标准化后的完整数据、时滞TimeLag\n",
    "    # 输出 时间序列数据 np.array\n",
    "    sequence_length = TimeLag + 1\n",
    "    result = []\n",
    "    for index in range(len(Normalized_pd) - sequence_length):\n",
    "        result.append(Normalized_pd.OpenScaled[index: index + sequence_length])\n",
    "    result = np.array(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 尝试训练函数式fusion模型\n",
    "def train_fusion_model(data_pd,padded_news_index,params,saveFile=r'/home/wells/SIOA/DowJonesPredict/SourceCode/ModelFile'):\n",
    "    checkpointer = ModelCheckpoint(filepath=saveFile + '\\checkpoint.hdf5',\n",
    "                                   monitor = 'val_mean_absolute_percentage_error',save_best_only=True)\n",
    "    result_pd = pd.DataFrame(columns=['TimeLags','RMSE','MAE','MAPE','RMSE_BP','MAE_BP','MAPE_BP'])\n",
    "    line_pd = pd.DataFrame(columns=['TimeLags','RMSE','MAE','MAPE','RMSE_BP','MAE_BP','MAPE_BP'])\n",
    "    \n",
    "    normalized_pd, MMScaler = Raw_Data_Normalized(dow_jons_pd)\n",
    "    TimeSeries = GetTimeSeriesData(normalized_pd, params['lstm_param']['TimeLag'])\n",
    "    print(TimeSeries.shape)\n",
    "    fusion_model = build_fusion_model(params)\n",
    "    \n",
    "    TrainSeries = TimeSeries[:round(params['lstm_param']['TrainTestSplit']*TimeSeries.shape[0]),:]\n",
    "    print(r'训练数据:',TrainSeries.shape)\n",
    "    TestSeries = TimeSeries[round(params['lstm_param']['TrainTestSplit']*TimeSeries.shape[0]):,:]\n",
    "    print(r'验证数据:',TestSeries.shape)\n",
    "    TrainSeries_X = TrainSeries[:,:-1]\n",
    "    TrainSeries_Y = TrainSeries[:,-1]\n",
    "    TestSeries_X = TestSeries[:,:-1]\n",
    "    TestSeries_Y = TestSeries[:,-1]\n",
    "    \n",
    "    # 张量化\n",
    "    Train_X = np.reshape(TrainSeries_X, (TrainSeries_X.shape[0], 1,TrainSeries_X.shape[1]))\n",
    "    Train_Y = np.reshape(TrainSeries_Y, (TrainSeries_Y.shape[0], 1,1))\n",
    "    Test_X = np.reshape(TestSeries_X, (TestSeries_X.shape[0], 1,TestSeries_X.shape[1]))\n",
    "    Test_Y = np.reshape(TestSeries_Y, (TestSeries_Y.shape[0], 1,1))\n",
    "    \n",
    "    #lstm_model.fit(Train_X,Train_Y,epochs=50,validation_split=0.3,batch_size=15)\n",
    "    padded_news_index = padded_news_index[params['lstm_param']['TimeLag']-1:]\n",
    "    train_news = padded_news_index[:round(params['lstm_param']['TrainTestSplit']*TimeSeries.shape[0])]\n",
    "    test_news = padded_news_index[round(params['lstm_param']['TrainTestSplit']*TimeSeries.shape[0]):]\n",
    "    checkpointer = ModelCheckpoint(filepath=saveFile + '\\checkpoint.hdf5',\n",
    "                                   monitor = 'val_mean_absolute_percentage_error',save_best_only=True)\n",
    "    Fitted_model = fusion_model.fit([train_news,Train_X], Train_Y, validation_split=0.3, \n",
    "                                    epochs=params['epochs'], batch_size=params['batch_size'],\n",
    "                                   callbacks = [checkpointer,],shuffle=False)\n",
    "#     RMSE,MAE,MAPE,Predict_y,True_Y = model_predict(Fitted_model,Test_X,Test_Y,MMScaler)\n",
    "#     line_pd['RMSE'] = [RMSE]\n",
    "#     line_pd['MAE'] = [MAE]\n",
    "#     line_pd['MAPE'] = [MAPE]\n",
    "#     line_pd['TimeLags'] = [params['lstm_param']['TimeLag']]\n",
    "#     print('RMSE:%s  ,MAE:%s  ,MAPE:%s '%(RMSE,MAE,MAPE))\n",
    "    return fusion_model,MMScaler,test_news,Test_X,Test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wells/Anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/wells/Anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# cnn涨跌预测\n",
    "\n",
    "params = {'cnn_param':{\n",
    "                       'n_filter':8,\n",
    "                       'filter_length':4,\n",
    "                       'n_pool':4,\n",
    "                       'kernel_size':32,\n",
    "                       'dense_dim':1, # 全连接层纬度\n",
    "#                        'lr':1e-5,\n",
    "#                        'epochs':5,\n",
    "#                        'batch_size':15,\n",
    "                       'embedding':{'imput_dim':count_diff_words(dow_jons_pd)+1,  # 语料库所有不同单词的个数\n",
    "                                    'output_dim':64,  # 词向量的长度\n",
    "                                    'imput_length':477 # 最长单日文本的长度\n",
    "                                   }\n",
    "                      },\n",
    "          'lstm_param':{\n",
    "                        'Timescale':1,\n",
    "#                         'lr': 0.0001,\n",
    "                        'nb_hidden_cell': [80,80,80],\n",
    "#                         'epochs': 1000,\n",
    "                        'dense_dim':8,\n",
    "#                         'batch_size': 100,\n",
    "                        'TimeLag': 7,\n",
    "                        'TrainTestSplit':0.7\n",
    "                      },\n",
    "          'batch_size': 15,\n",
    "          'epochs': 100,\n",
    "          'lr':1e-4,\n",
    "         }\n",
    "\n",
    "\n",
    "fusion_model = build_fusion_model(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1980, 8)\n",
      "训练数据: (1386, 8)\n",
      "验证数据: (594, 8)\n",
      "WARNING:tensorflow:From /home/wells/Anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 970 samples, validate on 416 samples\n",
      "Epoch 1/100\n",
      "970/970 [==============================] - 59s 61ms/step - loss: 0.4360 - mean_absolute_error: 0.6162 - mean_absolute_percentage_error: 71.3966 - val_loss: 0.0476 - val_mean_absolute_error: 0.2150 - val_mean_absolute_percentage_error: 39.6953\n",
      "Epoch 2/100\n",
      "970/970 [==============================] - 55s 57ms/step - loss: 0.1576 - mean_absolute_error: 0.3423 - mean_absolute_percentage_error: 39.3192 - val_loss: 0.0031 - val_mean_absolute_error: 0.0493 - val_mean_absolute_percentage_error: 8.8608\n",
      "Epoch 3/100\n",
      "970/970 [==============================] - 56s 57ms/step - loss: 0.0681 - mean_absolute_error: 0.1942 - mean_absolute_percentage_error: 22.7010 - val_loss: 0.0044 - val_mean_absolute_error: 0.0610 - val_mean_absolute_percentage_error: 11.8480\n",
      "Epoch 4/100\n",
      "970/970 [==============================] - 56s 58ms/step - loss: 0.0455 - mean_absolute_error: 0.1399 - mean_absolute_percentage_error: 17.0085 - val_loss: 0.0098 - val_mean_absolute_error: 0.0960 - val_mean_absolute_percentage_error: 18.3914\n",
      "Epoch 5/100\n",
      "970/970 [==============================] - 56s 58ms/step - loss: 0.0419 - mean_absolute_error: 0.1314 - mean_absolute_percentage_error: 16.0859 - val_loss: 0.0103 - val_mean_absolute_error: 0.0986 - val_mean_absolute_percentage_error: 18.8656\n",
      "Epoch 6/100\n",
      "970/970 [==============================] - 55s 57ms/step - loss: 0.0443 - mean_absolute_error: 0.1382 - mean_absolute_percentage_error: 16.8969 - val_loss: 0.0113 - val_mean_absolute_error: 0.1036 - val_mean_absolute_percentage_error: 19.8062\n",
      "Epoch 7/100\n",
      "970/970 [==============================] - 56s 58ms/step - loss: 0.0387 - mean_absolute_error: 0.1299 - mean_absolute_percentage_error: 15.9489 - val_loss: 0.0095 - val_mean_absolute_error: 0.0943 - val_mean_absolute_percentage_error: 18.0518\n",
      "Epoch 8/100\n",
      "970/970 [==============================] - 56s 58ms/step - loss: 0.0279 - mean_absolute_error: 0.1083 - mean_absolute_percentage_error: 13.0654 - val_loss: 0.0024 - val_mean_absolute_error: 0.0438 - val_mean_absolute_percentage_error: 8.5670\n",
      "Epoch 9/100\n",
      "970/970 [==============================] - 56s 58ms/step - loss: 0.0252 - mean_absolute_error: 0.1011 - mean_absolute_percentage_error: 12.0817 - val_loss: 7.1005e-04 - val_mean_absolute_error: 0.0202 - val_mean_absolute_percentage_error: 4.0267\n",
      "Epoch 10/100\n",
      "970/970 [==============================] - 56s 57ms/step - loss: 0.0219 - mean_absolute_error: 0.0958 - mean_absolute_percentage_error: 11.3388 - val_loss: 6.6528e-04 - val_mean_absolute_error: 0.0197 - val_mean_absolute_percentage_error: 3.9310\n",
      "Epoch 11/100\n",
      "970/970 [==============================] - 56s 58ms/step - loss: 0.0182 - mean_absolute_error: 0.0927 - mean_absolute_percentage_error: 11.0453 - val_loss: 4.0014e-04 - val_mean_absolute_error: 0.0152 - val_mean_absolute_percentage_error: 2.9951\n",
      "Epoch 12/100\n",
      "970/970 [==============================] - 60s 62ms/step - loss: 0.0161 - mean_absolute_error: 0.0898 - mean_absolute_percentage_error: 10.8436 - val_loss: 7.4671e-04 - val_mean_absolute_error: 0.0220 - val_mean_absolute_percentage_error: 4.3388\n",
      "Epoch 13/100\n",
      "970/970 [==============================] - 56s 58ms/step - loss: 0.0144 - mean_absolute_error: 0.0904 - mean_absolute_percentage_error: 10.7867 - val_loss: 4.4169e-04 - val_mean_absolute_error: 0.0160 - val_mean_absolute_percentage_error: 3.1696\n",
      "Epoch 14/100\n",
      "970/970 [==============================] - 55s 57ms/step - loss: 0.0153 - mean_absolute_error: 0.0946 - mean_absolute_percentage_error: 11.3080 - val_loss: 6.2769e-04 - val_mean_absolute_error: 0.0199 - val_mean_absolute_percentage_error: 3.9275\n",
      "Epoch 15/100\n",
      "970/970 [==============================] - 56s 58ms/step - loss: 0.0149 - mean_absolute_error: 0.0933 - mean_absolute_percentage_error: 11.1850 - val_loss: 7.6718e-04 - val_mean_absolute_error: 0.0228 - val_mean_absolute_percentage_error: 4.4737\n",
      "Epoch 16/100\n",
      "970/970 [==============================] - 55s 57ms/step - loss: 0.0133 - mean_absolute_error: 0.0896 - mean_absolute_percentage_error: 10.8191 - val_loss: 0.0011 - val_mean_absolute_error: 0.0282 - val_mean_absolute_percentage_error: 5.4882\n",
      "Epoch 17/100\n",
      "970/970 [==============================] - 55s 57ms/step - loss: 0.0131 - mean_absolute_error: 0.0901 - mean_absolute_percentage_error: 10.7499 - val_loss: 9.9855e-04 - val_mean_absolute_error: 0.0270 - val_mean_absolute_percentage_error: 5.2719\n",
      "Epoch 18/100\n",
      "970/970 [==============================] - 55s 56ms/step - loss: 0.0129 - mean_absolute_error: 0.0907 - mean_absolute_percentage_error: 10.8229 - val_loss: 5.1280e-04 - val_mean_absolute_error: 0.0175 - val_mean_absolute_percentage_error: 3.4578\n",
      "Epoch 19/100\n",
      "970/970 [==============================] - 56s 58ms/step - loss: 0.0146 - mean_absolute_error: 0.0950 - mean_absolute_percentage_error: 11.3839 - val_loss: 6.7741e-04 - val_mean_absolute_error: 0.0211 - val_mean_absolute_percentage_error: 4.1499\n",
      "Epoch 20/100\n",
      "970/970 [==============================] - 55s 57ms/step - loss: 0.0135 - mean_absolute_error: 0.0914 - mean_absolute_percentage_error: 10.9650 - val_loss: 9.8772e-04 - val_mean_absolute_error: 0.0268 - val_mean_absolute_percentage_error: 5.2334\n",
      "Epoch 21/100\n",
      "970/970 [==============================] - 55s 57ms/step - loss: 0.0129 - mean_absolute_error: 0.0904 - mean_absolute_percentage_error: 10.8157 - val_loss: 4.9205e-04 - val_mean_absolute_error: 0.0170 - val_mean_absolute_percentage_error: 3.3684\n",
      "Epoch 22/100\n",
      "970/970 [==============================] - 55s 56ms/step - loss: 0.0126 - mean_absolute_error: 0.0881 - mean_absolute_percentage_error: 10.4592 - val_loss: 7.7270e-04 - val_mean_absolute_error: 0.0230 - val_mean_absolute_percentage_error: 4.5024\n",
      "Epoch 23/100\n",
      "970/970 [==============================] - 56s 58ms/step - loss: 0.0117 - mean_absolute_error: 0.0863 - mean_absolute_percentage_error: 10.2919 - val_loss: 5.3245e-04 - val_mean_absolute_error: 0.0181 - val_mean_absolute_percentage_error: 3.5598\n",
      "Epoch 24/100\n",
      "970/970 [==============================] - 57s 59ms/step - loss: 0.0151 - mean_absolute_error: 0.0961 - mean_absolute_percentage_error: 11.5292 - val_loss: 8.7334e-04 - val_mean_absolute_error: 0.0250 - val_mean_absolute_percentage_error: 4.8745\n",
      "Epoch 25/100\n",
      "970/970 [==============================] - 56s 58ms/step - loss: 0.0135 - mean_absolute_error: 0.0932 - mean_absolute_percentage_error: 11.1747 - val_loss: 0.0013 - val_mean_absolute_error: 0.0323 - val_mean_absolute_percentage_error: 6.2528\n",
      "Epoch 26/100\n",
      "970/970 [==============================] - 57s 58ms/step - loss: 0.0112 - mean_absolute_error: 0.0854 - mean_absolute_percentage_error: 10.1733 - val_loss: 7.2568e-04 - val_mean_absolute_error: 0.0222 - val_mean_absolute_percentage_error: 4.3429\n",
      "Epoch 27/100\n",
      "970/970 [==============================] - 59s 61ms/step - loss: 0.0120 - mean_absolute_error: 0.0880 - mean_absolute_percentage_error: 10.5799 - val_loss: 5.0670e-04 - val_mean_absolute_error: 0.0176 - val_mean_absolute_percentage_error: 3.4640\n",
      "Epoch 28/100\n",
      "970/970 [==============================] - 56s 58ms/step - loss: 0.0116 - mean_absolute_error: 0.0882 - mean_absolute_percentage_error: 10.5815 - val_loss: 8.5575e-04 - val_mean_absolute_error: 0.0247 - val_mean_absolute_percentage_error: 4.8178\n",
      "Epoch 29/100\n",
      "970/970 [==============================] - 56s 58ms/step - loss: 0.0121 - mean_absolute_error: 0.0882 - mean_absolute_percentage_error: 10.5257 - val_loss: 7.4141e-04 - val_mean_absolute_error: 0.0225 - val_mean_absolute_percentage_error: 4.4054\n",
      "Epoch 30/100\n",
      "970/970 [==============================] - 55s 57ms/step - loss: 0.0111 - mean_absolute_error: 0.0858 - mean_absolute_percentage_error: 10.2438 - val_loss: 6.7107e-04 - val_mean_absolute_error: 0.0211 - val_mean_absolute_percentage_error: 4.1419\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "970/970 [==============================] - 55s 57ms/step - loss: 0.0103 - mean_absolute_error: 0.0821 - mean_absolute_percentage_error: 9.8525 - val_loss: 0.0013 - val_mean_absolute_error: 0.0323 - val_mean_absolute_percentage_error: 6.2496\n",
      "Epoch 32/100\n",
      "970/970 [==============================] - 56s 58ms/step - loss: 0.0122 - mean_absolute_error: 0.0888 - mean_absolute_percentage_error: 10.6145 - val_loss: 5.9048e-04 - val_mean_absolute_error: 0.0193 - val_mean_absolute_percentage_error: 3.7938\n",
      "Epoch 33/100\n",
      "970/970 [==============================] - 56s 58ms/step - loss: 0.0115 - mean_absolute_error: 0.0875 - mean_absolute_percentage_error: 10.4563 - val_loss: 7.5670e-04 - val_mean_absolute_error: 0.0227 - val_mean_absolute_percentage_error: 4.4532\n",
      "Epoch 34/100\n",
      "970/970 [==============================] - 55s 56ms/step - loss: 0.0127 - mean_absolute_error: 0.0902 - mean_absolute_percentage_error: 10.6833 - val_loss: 5.6066e-04 - val_mean_absolute_error: 0.0185 - val_mean_absolute_percentage_error: 3.6471\n",
      "Epoch 35/100\n",
      "970/970 [==============================] - 55s 57ms/step - loss: 0.0128 - mean_absolute_error: 0.0895 - mean_absolute_percentage_error: 10.6494 - val_loss: 7.1876e-04 - val_mean_absolute_error: 0.0220 - val_mean_absolute_percentage_error: 4.3126\n",
      "Epoch 36/100\n",
      "970/970 [==============================] - 56s 57ms/step - loss: 0.0116 - mean_absolute_error: 0.0871 - mean_absolute_percentage_error: 10.4387 - val_loss: 4.6705e-04 - val_mean_absolute_error: 0.0167 - val_mean_absolute_percentage_error: 3.2898\n",
      "Epoch 37/100\n",
      "970/970 [==============================] - 60s 62ms/step - loss: 0.0114 - mean_absolute_error: 0.0853 - mean_absolute_percentage_error: 10.1625 - val_loss: 0.0011 - val_mean_absolute_error: 0.0291 - val_mean_absolute_percentage_error: 5.6456\n",
      "Epoch 38/100\n",
      "970/970 [==============================] - 56s 58ms/step - loss: 0.0107 - mean_absolute_error: 0.0843 - mean_absolute_percentage_error: 10.1064 - val_loss: 8.6769e-04 - val_mean_absolute_error: 0.0249 - val_mean_absolute_percentage_error: 4.8570\n",
      "Epoch 39/100\n",
      "970/970 [==============================] - 56s 57ms/step - loss: 0.0106 - mean_absolute_error: 0.0834 - mean_absolute_percentage_error: 10.0024 - val_loss: 0.0012 - val_mean_absolute_error: 0.0302 - val_mean_absolute_percentage_error: 5.8570\n",
      "Epoch 40/100\n",
      "970/970 [==============================] - 56s 58ms/step - loss: 0.0104 - mean_absolute_error: 0.0822 - mean_absolute_percentage_error: 9.8248 - val_loss: 9.4982e-04 - val_mean_absolute_error: 0.0263 - val_mean_absolute_percentage_error: 5.1276\n",
      "Epoch 41/100\n",
      "970/970 [==============================] - 56s 58ms/step - loss: 0.0103 - mean_absolute_error: 0.0834 - mean_absolute_percentage_error: 9.9461 - val_loss: 7.5710e-04 - val_mean_absolute_error: 0.0226 - val_mean_absolute_percentage_error: 4.4307\n",
      "Epoch 42/100\n",
      "970/970 [==============================] - 57s 58ms/step - loss: 0.0109 - mean_absolute_error: 0.0840 - mean_absolute_percentage_error: 10.0182 - val_loss: 0.0010 - val_mean_absolute_error: 0.0272 - val_mean_absolute_percentage_error: 5.3049\n",
      "Epoch 43/100\n",
      "970/970 [==============================] - 57s 58ms/step - loss: 0.0110 - mean_absolute_error: 0.0856 - mean_absolute_percentage_error: 10.2582 - val_loss: 9.0726e-04 - val_mean_absolute_error: 0.0254 - val_mean_absolute_percentage_error: 4.9623\n",
      "Epoch 44/100\n",
      "970/970 [==============================] - 55s 57ms/step - loss: 0.0113 - mean_absolute_error: 0.0836 - mean_absolute_percentage_error: 9.9050 - val_loss: 4.8370e-04 - val_mean_absolute_error: 0.0170 - val_mean_absolute_percentage_error: 3.3588\n",
      "Epoch 45/100\n",
      "435/970 [============>.................] - ETA: 25s - loss: 0.0152 - mean_absolute_error: 0.0972 - mean_absolute_percentage_error: 10.3953"
     ]
    }
   ],
   "source": [
    "padded_news_index = propose_news_array(dow_jons_pd, params['cnn_param']['embedding']['imput_length'])\n",
    "Fitted_model,MMScaler,test_news,Test_X,Test_Y = train_fusion_model(dow_jons_pd,padded_news_index,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE,MAE,MAPE,predict_array,y_test = model_predict(Fitted_model,[test_news[:Test_X.shape[0]],Test_X],Test_Y,MMScaler,\n",
    "              save=r'/home/wells/SIOA/DowJonesPredict/SourceCode/PicSave')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
